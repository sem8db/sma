import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import squarify
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# Load the dataset
data = pd.read_csv('data.csv')

# Step 1: Handle missing values
# Impute numerical columns with mean
numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns
num_imputer = SimpleImputer(strategy='mean')
data[numerical_cols] = num_imputer.fit_transform(data[numerical_cols])

# Impute categorical columns with the most frequent value
categorical_cols = data.select_dtypes(include=['object']).columns
cat_imputer = SimpleImputer(strategy='most_frequent')
data[categorical_cols] = cat_imputer.fit_transform(data[categorical_cols])

# Step 2: Remove outliers using the IQR method
def remove_outliers(df, cols):
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df

# B831 – Arya Sahane

# Apply outlier removal to numerical columns
data = remove_outliers(data, numerical_cols)

# Step 3: Standardize numerical columns
scaler = StandardScaler()
data[numerical_cols] = scaler.fit_transform(data[numerical_cols])

# Save the cleaned dataset
output_file_path = 'cleaned_data.csv'
data.to_csv(output_file_path, index=False)
print(f"Data cleaned, visualized, and saved to {output_file_path}")

# Read the cleaned data CSV file
cleaned_data = pd.read_csv('cleaned_data.csv')
# Print the contents of the CSV file
print(cleaned_data.head())

# Output:

# Step 4: Perform Exploratory Data Analysis (EDA) and Visualization

# Pie Chart
plt.figure(figsize=(8, 8))
data['Style'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)
plt.title('Pie Chart of Beer Styles')
plt.ylabel('')
plt.show()

# B831 – Arya Sahane

# Heat Map
plt.figure(figsize=(12, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Heatmap of Correlation Matrix')
plt.show()

# Histogram
plt.figure(figsize=(10, 6))
data['ABV'].hist(bins=20, color='skyblue', edgecolor='black')
plt.title('Histogram of ABV (Alcohol By Volume)')
plt.xlabel('ABV')
plt.ylabel('Frequency')
plt.show()

# B831 – Arya Sahane

# Line Chart
plt.figure(figsize=(10, 6))
data.groupby('Style')['ABV'].mean().sort_values().plot(kind='line', marker='o', color='green')
plt.title('Line Chart of Average ABV by Style')
plt.xlabel('Style')
plt.ylabel('Average ABV')
plt.xticks(rotation=90)
plt.show()

# Scatter Plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x='OG', y='FG', hue='Style', data=data)
plt.title('Scatter Plot of OG vs FG by Style')
plt.xlabel('Original Gravity (OG)')
plt.ylabel('Final Gravity (FG)')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

# B831 – Arya Sahane

# Tree Map
style_counts = data['Style'].value_counts()
plt.figure(figsize=(12, 8))
squarify.plot(sizes=style_counts.values, label=style_counts.index, alpha=0.8)
plt.title('Tree Map of Beer Styles')
plt.axis('off')
plt.show()

# Conclusion:
# Thus, EDA and data visualization help in gaining insights, identifying potential issues,
# and preparing the data for further analysis.

# B831 – Arya Sahane
